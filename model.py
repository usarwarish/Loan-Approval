# -*- coding: utf-8 -*-
"""loan approval.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iUHmBrV8qRpP6-uWyn2ER-PZreIGwHA6
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
import warnings
warnings.filterwarnings("ignore")
from sklearn.metrics import accuracy_score

import pandas as pd

loan_data  = pd.read_csv("https://raw.githubusercontent.com/dphi-official/Datasets/master/Loan_Data/loan_train.csv" )

loan_data.head()

loan_data.columns

df = loan_data
df = df.iloc[:,1:]
print( df['Dependents'].unique())

df.info()

X = df.drop(['Loan_ID', 'Loan_Status'],axis=1)
y = df.iloc[:,-1:]

print(X.head())
print(y.head())

features = X.columns
features

df['Loan_Status'].count()

df['Loan_Status'].value_counts()

y["Loan_Status"].value_counts().plot.bar(title = 'Loan_Status')

y["Loan_Status"].value_counts(normalize=True).plot.bar(title = 'Loan_Status')

train =df

train["Gender"].count()

X["Gender"].value_counts()

X['Gender'].value_counts(normalize=True).plot.bar(title= 'Gender')



train["Married"].count()

train["Married"].value_counts()

train['Married'].value_counts(normalize=True).plot.bar(title= 'Married')



train["Self_Employed"].count()

train["Self_Employed"].value_counts()

train['Self_Employed'].value_counts(normalize=True).plot.bar(title='Self_Employed')



train["Credit_History"].count()

train["Credit_History"].value_counts()

train['Credit_History'].value_counts(normalize=True).plot.bar(title='Credit_History')

train['Dependents'].replace('3+',3,inplace=True)

X['Dependents'].replace('3+',3,inplace=True)
X

matrix = train.corr()
f, ax = plt.subplots(figsize=(10, 12))
sns.heatmap(matrix, vmax=.8, square=True, cmap="BuPu",annot=True);

"""Applicant Income and Credit History"""



train.isnull().sum()

train["Gender"].fillna(train["Gender"].mode()[0],inplace=True)
train["Married"].fillna(train["Married"].mode()[0],inplace=True)
train['Dependents'].fillna(train["Dependents"].mode()[0],inplace=True)
train["Self_Employed"].fillna(train["Self_Employed"].mode()[0],inplace=True)
train["Credit_History"].fillna(train["Credit_History"].mode()[0],inplace=True)



train.isnull().sum()

train["Loan_Amount_Term"].value_counts()

train["Loan_Amount_Term"].fillna(train["Loan_Amount_Term"].mode()[0],inplace=True)

train["LoanAmount"].fillna(train["LoanAmount"].median(),inplace=True)

train.isnull().sum()

TRAIN = train

#sns.distplot(train["LoanAmount"]);

#train['LoanAmount'].hist(bins=20)



"""LOG TRANSFORMATION"""

#train['LoanAmount_log'] = np.log(train['LoanAmount'])
#train['LoanAmount_log'].hist(bins=20)

#sns.distplot(train["LoanAmount_log"])



"""FEATURE ENGG"""

#train["TotalIncome"]=train["ApplicantIncome"]+train["CoapplicantIncome"]
#train[["TotalIncome"]].head()

#sns.distplot(train["TotalIncome"])

"""Skewness to be rectified"""

#train["TotalIncome_log"]=np.log(train["TotalIncome"])
#sns.distplot(train["TotalIncome_log"])

"""Now the distribution looks much closer to normal and effect of extreme values has been significantly subsided.


"""

#train["EMI"]=train["LoanAmount"]/train["Loan_Amount_Term"]
#train[["EMI"]].head()

#sns.distplot(train["EMI"])

#train["Balance_Income"] = train["TotalIncome"]-train["EMI"]*1000 # To make the units equal we multiply with 1000

#train[["Balance_Income"]].head()

#train=train.drop(["ApplicantIncome","CoapplicantIncome","LoanAmount","Loan_Amount_Term"],axis=1)

#train.head()

#matrix = train.corr()
#f, ax = plt.subplots(figsize=(10, 12))
#sns.heatmap(matrix, vmax=.8, square=True, cmap="BuPu",annot=True);



"""Model Buildingg"""

#X=train.drop(["Loan_Status", "Loan_ID"],axis=1)
#y = train["Loan_Status"]

#X.head()



#X = pd.get_dummies(X)
#X

#df['Loan_Status'] = df['Loan_Status'].astype(int)
#df

#df.info()

#train=pd.get_dummies(train)
#train.head()



from sklearn.model_selection import train_test_split
#X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=1)



from sklearn.ensemble import RandomForestClassifier
#forest_model = RandomForestClassifier(random_state=1,max_depth=10,n_estimators=50)
#forest_model.fit(X_train,y_train)

#pred_cv_forest=forest_model.predict(X_test)
#score_forest = accuracy_score(pred_cv_forest,y_test)*100
#print(score_forest)



#@title Random forest with Grid search

from sklearn.model_selection import GridSearchCV

#paramgrid = {'max_depth': list(range(1,20,2)),'n_estimators':list(range(1,200,20))}

#grid_search = GridSearchCV( RandomForestClassifier(random_state=1), paramgrid)

#grid_search.fit(X_train,y_train)

#grid_search.best_estimator_

#grid_forest_model = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
#                       criterion='gini', max_depth=5, max_features='auto',
#                       max_leaf_nodes=None, max_samples=None,
#                       min_impurity_decrease=0.0, min_impurity_split=None,
#                       min_samples_leaf=1, min_samples_split=2,
#                       min_weight_fraction_leaf=0.0, n_estimators=181,
#                       n_jobs=None, oob_score=False, random_state=1, verbose=0,
#                       warm_start=False
#)

#grid_forest_model.fit(X_train,y_train)

#pred_grid_forest = grid_forest_model.predict(X_test)

#score_grid_forest = accuracy_score(pred_grid_forest,y_test)*100

#print(score_grid_forest)



#importances = pd.Series(forest_model.feature_importances_,index=X.columns)
#importances.plot(kind='barh', figsize=(12,8))

"""## WORKING ON TEST DATA"""

test_data = pd.read_csv('https://raw.githubusercontent.com/dphi-official/Datasets/master/Loan_Data/loan_test.csv')
test = test_data
test_data

test.isnull().sum()

test["Gender"].fillna(test["Gender"].mode()[0],inplace=True)
test["Married"].fillna(test["Married"].mode()[0],inplace=True)
test['Dependents'].fillna(test["Dependents"].mode()[0],inplace=True)
test["Self_Employed"].fillna(test["Self_Employed"].mode()[0],inplace=True)
test["Credit_History"].fillna(test["Credit_History"].mode()[0],inplace=True)

test.isnull().sum()

test["Loan_Amount_Term"].fillna(test["Loan_Amount_Term"].mode()[0],inplace=True)
test["LoanAmount"].fillna(test["LoanAmount"].median(),inplace=True)
test.isnull().sum()
test['Dependents'].replace('3+',3,inplace=True)

TEST = test

#test["TotalIncome"]=test["ApplicantIncome"]+test["CoapplicantIncome"]
#test[["TotalIncome"]].head()

#sns.distplot(test["TotalIncome"])

#test["TotalIncome_log"]=np.log(train["TotalIncome"])
#sns.distplot(test["TotalIncome_log"])



#test["LoanAmount_log"]=np.log( test["LoanAmount"])
#test['LoanAmount_log'].hist(bins=20)

#sns.distplot(test["LoanAmount_log"])



#test["EMI"]=test["LoanAmount"]/test["Loan_Amount_Term"]
#sns.distplot(test["EMI"])



#test["Balance_Income"] = test["TotalIncome"]-test["EMI"]

#test = test.drop(["ApplicantIncome","CoapplicantIncome","LoanAmount","Loan_Amount_Term"],axis=1)
#test.head()

#test['Dependents'].unique()

#test=test.drop("Loan_ID",axis=1)

#test.head(3)



#test=pd.get_dummies(test)

#test

#pred_grid_forest_test = grid_forest_model.predict(test)

#output = pd.DataFrame(pred_grid_forest_test,columns=['prediction'])
#output.to_csv('my_submission.csv', index=False)
#print("Your submission was successfully saved!")





"""LOGISTIC REGRESSION"""

#from sklearn.linear_model import LogisticRegression
#logistic_model = LogisticRegression(random_state=1)
#

#logistic_model.fit(X_train,y_train)



TEST = TEST.drop(["Loan_ID"],axis=1)
TEST

y=TRAIN['Loan_Status']
TRAIN= TRAIN.drop(["Loan_ID"],axis=1)
TRAIN



train_df_encoded = pd.get_dummies(TRAIN)
train_df_encoded

X = train_df_encoded.drop(columns='Loan_Status')
X

test_df_encoded = pd.get_dummies(TEST)
test_df_encoded

#values = [np.array( [0,	1668.0,	110.0,	360.0,	1.0,	5416.0,	8.422223,	4.700480,	0.305556,	5415.694444,	1,	0,	0,	0,	0,	1,	0,	1,	3748])]

#print( rf_clf.predict(values))

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,stratify =y,random_state =42)

from sklearn.ensemble import RandomForestClassifier

rf_clf = RandomForestClassifier(n_estimators=100,max_depth=3,min_samples_leaf = 10)
rf_clf.fit(X_train,y_train)
y_pred = rf_clf.predict(X_train)
#print("Train F1 Score ", f1_score(y_train,y_pred))
print("Train Accuracy ", accuracy_score(y_train,y_pred))

#print("Validation Mean F1 Score: ",cross_val_score(rf_clf,X_train,y_train,cv=5,scoring='f1_macro').mean())
#print("Validation Mean Accuracy: ",cross_val_score(rf_clf,X_train,y_train,cv=5,scoring='accuracy').mean())

y_pred = rf_clf.predict(X_test)
print("Test Accuracy: ",accuracy_score(y_test,y_pred))
#print("Test F1 Score: ",f1_score(y_test,y_pred))
#print("Confusion Matrix on Test Data")
#pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)

pred = rf_clf.predict(test_df_encoded)


output = pd.DataFrame(pred, columns=['prediction'])
output.to_csv('my_submission_3.csv', index=False)
print("Your submission was successfully saved!")

print(pred)

"""### DEPLOYMENT"""


"""### DEPLOYMENT"""
import pickle
filename = 'myModel.pkl'
pickle.dump(rf_clf, open(filename, 'wb'))